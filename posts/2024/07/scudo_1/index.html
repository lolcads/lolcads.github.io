<!doctype html><html lang=en dir=ltr><head><title>Timing Attack Experiments against Scudo (Part 2) :: lolcads tech blog</title>
<meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Attempting Timing Attacks against Scudo In this second blog post we will take a different approach for attacking Scudo , i.e. we will try to the measure execution times for calls to malloc and hope to be able to derive a portion of the internal state of the allocator (i.e. perform side channel attacks). The version of Scudo considered in this blog post is 161cca266a9d0b6deb5f1fd2de8ad543649a7fa1 .
There will be almost only negative results (which means I unfortunately could not make it work), except for one. The main conclusion we can draw from this post is that Scudo is not designed to mitigate timing attacks! This follows from trying to leak a piece of information and then accidentally leaking a different and unclassified piece.
"><meta name=keywords content="Android,Side Channel Attack,Timing Attack,JNI,DamnVulnerableApp,Scudo,Heap Exploitation"><meta name=robots content="noodp"><link rel=manifest href=/manifest.json><meta property="og:url" content="https://lolcads.github.io/posts/2024/07/scudo_1/"><meta property="og:site_name" content="lolcads tech blog"><meta property="og:title" content="Timing Attack Experiments against Scudo (Part 2)"><meta property="og:description" content="Attempting Timing Attacks against Scudo In this second blog post we will take a different approach for attacking Scudo , i.e. we will try to the measure execution times for calls to malloc and hope to be able to derive a portion of the internal state of the allocator (i.e. perform side channel attacks). The version of Scudo considered in this blog post is 161cca266a9d0b6deb5f1fd2de8ad543649a7fa1 .
There will be almost only negative results (which means I unfortunately could not make it work), except for one. The main conclusion we can draw from this post is that Scudo is not designed to mitigate timing attacks! This follows from trying to leak a piece of information and then accidentally leaking a different and unclassified piece."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-07-26T16:46:21+01:00"><meta property="article:modified_time" content="2024-07-26T16:46:21+01:00"><meta property="article:tag" content="Android"><meta property="article:tag" content="Side Channel Attack"><meta property="article:tag" content="Timing Attack"><meta property="article:tag" content="JNI"><meta property="article:tag" content="DamnVulnerableApp"><meta property="article:tag" content="Scudo"><meta name=twitter:card content="summary"><meta name=twitter:title content="Timing Attack Experiments against Scudo (Part 2)"><meta name=twitter:description content="Attempting Timing Attacks against Scudo In this second blog post we will take a different approach for attacking Scudo , i.e. we will try to the measure execution times for calls to malloc and hope to be able to derive a portion of the internal state of the allocator (i.e. perform side channel attacks). The version of Scudo considered in this blog post is 161cca266a9d0b6deb5f1fd2de8ad543649a7fa1 .
There will be almost only negative results (which means I unfortunately could not make it work), except for one. The main conclusion we can draw from this post is that Scudo is not designed to mitigate timing attacks! This follows from trying to leak a piece of information and then accidentally leaking a different and unclassified piece."><link rel=canonical href=https://lolcads.github.io/posts/2024/07/scudo_1/><link rel="shortcut icon" href=/favicon.ico><link rel=stylesheet href=/css/index.min.c860e17f20d9f258820c02bf7ab3f57c9595d0bc21dede7eda08ccd63ba3f4cc.css></head><body class="flex flex-col min-h-screen w-full bg-slate-50 dark:bg-gray-800"><header class="flex flex-none justify-center z-10"><div class="flex flex-row gap justify-between w-full max-w-4xl lg:max-w-5xl h-12 mt-3"><div class="flex-none ml-2 md:ml-0"><a href=/><img class="h-12 w-12 rounded-full object-cover bg-gray-100" src=/logo.png alt=logo></a></div><div class=flex-1></div><div class=flex-none><nav class="h-full static"><button id=navbar-menu-toggle type=button class="inline-flex items-center p-2 text-sm text-slate-800 dark:text-slate-200 rounded-lg md:hidden" aria-controls=navbar-menu aria-expanded=false>
<span class=sr-only>Open main menu</span>
<i class="w-8 h-8"><svg class="icon icon-tabler icon-tabler-menu-2" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 6h16"/><path d="M4 12h16"/><path d="M4 18h16"/></svg></i></button><div class="absolute md:static top-16 left-0 right-0 z-50 hidden w-full md:block md:w-auto" id=navbar-menu><ul class="flex flex-col mx-2 md:mx-0 md:flex-row md:border-0 rounded-sm md:rounded-full px-3 text-base font-medium text-slate-800 dark:text-slate-200 shadow-lg bg-white dark:bg-gray-600 shadow-slate-800/5 dark:shadow-slate-200/5 ring-1 ring-slate-900/5 dark:ring-slate-100/5"><li id=post><a class="block px-3 py-3 hover:text-emerald-600 text-emerald-600" href=/posts/ title=Blog>Blog</a></li><li id=about><a class="block px-3 py-3 hover:text-emerald-600" href=/about/ title=About>About</a></li><li id=contact><a class="block px-3 py-3 hover:text-emerald-600" href=/contact/ title=Contact>Contact</a></li></ul></div></nav></div><div class="flex-none mx-1"></div><div class="flex-none md:hidden"><a href=/search/ class="inline-flex items-center p-2 text-sm text-slate-800 dark:text-slate-200 rounded-lg" aria-controls=navbar-menu aria-expanded=false><span class=sr-only>Search</span>
<i class="w-8 h-8"><svg class="icon icon-tabler icon-tabler-search" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M10 10m-7 0a7 7 0 1014 0A7 7 0 103 10"/><path d="M21 21l-6-6"/></svg></i></a></div><div class="darkmode-toggle flex flex-none mr-2 md:mr-0"><label for=darkmode-toggle class="flex items-center px-3 cursor-pointer rounded-full bg-gray-100 dark:bg-gray-600" title="Toggle dark mode"><input name=darkmode-toggle id=darkmode-toggle type=checkbox class="sr-only peer" aria-label="Toggle dark mode"><div class="group flex flex-row gap-1 justify-center h-8 px-1 rounded-full bg-white dark:bg-gray-700"><i class="h-6 w-6 flex-none rounded-full bg-yellow-400 place-self-center peer-checked:group-[]:invisible"><svg class="icon icon-tabler icon-tabler-brightness-down" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M12 12m-3 0a3 3 0 106 0 3 3 0 10-6 0"/><path d="M12 5v.01"/><path d="M17 7v.01"/><path d="M19 12v.01"/><path d="M17 17v.01"/><path d="M12 19v.01"/><path d="M7 17v.01"/><path d="M5 12v.01"/><path d="M7 7v.01"/></svg>
</i><i class="h-6 w-6 flex-none rounded-full place-self-center invisible peer-checked:group-[]:visible"><svg class="icon icon-tabler icon-tabler-moon-stars" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M12 3c.132.0.263.0.393.0a7.5 7.5.0 007.92 12.446A9 9 0 1112 2.992z"/><path d="M17 4a2 2 0 002 2 2 2 0 00-2 2 2 2 0 00-2-2 2 2 0 002-2"/><path d="M19 11h2m-1-1v2"/></svg></i></div></label></div></div></header><main class="flex flex-auto justify-center"><div class="w-full max-w-4xl lg:max-w-5xl"><div class="flex flex-col mt-6 mx-2 md:mx-0 rounded-lg overflow-hidden shadow-md bg-white dark:bg-gray-700"><div><a href=/posts/2024/07/scudo_1/></a></div><div class="flex flex-col gap-y-3 p-6"><h1 class="text-4xl font-semibold text-slate-800 dark:text-slate-100"><a href=/posts/2024/07/scudo_1/>Timing Attack Experiments against Scudo (Part 2)</a></h1><ul class="flex flex-row flex-wrap text-slate-500 dark:text-slate-300"><li><a href=/tags/android/ class="flex flex-row text-sm mr-2 py-1"><i class="h-5 w-5 flex-none"><svg class="icon icon-tabler icon-tabler-hash" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M5 9h14"/><path d="M5 15h14"/><path d="M11 4 7 20"/><path d="M17 4l-4 16"/></svg>
</i><span class=ml-0>Android</span></a></li><li><a href=/tags/side-channel-attack/ class="flex flex-row text-sm mr-2 py-1"><i class="h-5 w-5 flex-none"><svg class="icon icon-tabler icon-tabler-hash" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M5 9h14"/><path d="M5 15h14"/><path d="M11 4 7 20"/><path d="M17 4l-4 16"/></svg>
</i><span class=ml-0>Side Channel Attack</span></a></li><li><a href=/tags/timing-attack/ class="flex flex-row text-sm mr-2 py-1"><i class="h-5 w-5 flex-none"><svg class="icon icon-tabler icon-tabler-hash" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M5 9h14"/><path d="M5 15h14"/><path d="M11 4 7 20"/><path d="M17 4l-4 16"/></svg>
</i><span class=ml-0>Timing Attack</span></a></li><li><a href=/tags/jni/ class="flex flex-row text-sm mr-2 py-1"><i class="h-5 w-5 flex-none"><svg class="icon icon-tabler icon-tabler-hash" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M5 9h14"/><path d="M5 15h14"/><path d="M11 4 7 20"/><path d="M17 4l-4 16"/></svg>
</i><span class=ml-0>JNI</span></a></li><li><a href=/tags/damnvulnerableapp/ class="flex flex-row text-sm mr-2 py-1"><i class="h-5 w-5 flex-none"><svg class="icon icon-tabler icon-tabler-hash" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M5 9h14"/><path d="M5 15h14"/><path d="M11 4 7 20"/><path d="M17 4l-4 16"/></svg>
</i><span class=ml-0>DamnVulnerableApp</span></a></li><li><a href=/tags/scudo/ class="flex flex-row text-sm mr-2 py-1"><i class="h-5 w-5 flex-none"><svg class="icon icon-tabler icon-tabler-hash" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M5 9h14"/><path d="M5 15h14"/><path d="M11 4 7 20"/><path d="M17 4l-4 16"/></svg>
</i><span class=ml-0>Scudo</span></a></li><li><a href=/tags/heap-exploitation/ class="flex flex-row text-sm mr-2 py-1"><i class="h-5 w-5 flex-none"><svg class="icon icon-tabler icon-tabler-hash" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M5 9h14"/><path d="M5 15h14"/><path d="M11 4 7 20"/><path d="M17 4l-4 16"/></svg>
</i><span class=ml-0>Heap Exploitation</span></a></li></ul><div class="flex flex-col gap-y-1 md:flex-row md:gap-y-0 md:gap-x-4 text-slate-500 dark:text-slate-300"><div class="flex flex-row text-base gap-x-1"><i class="h-6 w-6 flex-none"><svg class="icon icon-tabler icon-tabler-calendar" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 7a2 2 0 012-2h12a2 2 0 012 2v12a2 2 0 01-2 2H6a2 2 0 01-2-2V7z"/><path d="M16 3v4"/><path d="M8 3v4"/><path d="M4 11h16"/><path d="M11 15h1"/><path d="M12 15v3"/></svg>
</i><time datetime=2024-07-26T16:46:21+01:00>2024-07-26</time></div><div class="flex flex-row text-base gap-x-1"><i class="h-6 w-6 flex-none"><svg class="icon icon-tabler icon-tabler-hourglass-high" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M6.5 7h11"/><path d="M6 20v-2a6 6 0 1112 0v2a1 1 0 01-1 1H7a1 1 0 01-1-1z"/><path d="M6 4v2a6 6 0 1012 0V4a1 1 0 00-1-1H7A1 1 0 006 4z"/></svg>
</i><span>22 minutes to read</span></div></div><div class="flex flex-col gap-y-1 md:flex-row md:gap-y-0 md:gap-x-4 text-slate-500 dark:text-slate-300"><div class="flex flex-row text-base gap-x-1"><i class="h-6 w-6 flex-none"><svg viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-user"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M8 7a4 4 0 108 0A4 4 0 008 7"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg>
</i><span>Pascal Kühnemann</span></div></div><section class="prose prose-slate dark:prose-invert w-full max-w-4xl lg:max-w-5xl mt-6"><h2>Table of Contents</h2><aside><nav id=TableOfContents><ul><li><a href=#experimental-setup>Experimental Setup</a></li><li><a href=#timing-attacks>Timing Attacks</a><ul><li><a href=#attacking-chunks-array>Attacking Chunks Array</a></li><li><a href=#attacking-secondary-cache>Attacking Secondary Cache</a></li></ul></li><li><a href=#conclusion>Conclusion</a></li></ul></nav></aside></section><article class="mt-6 w-full max-w-4xl lg:max-w-5xl prose prose-slate dark:prose-invert prose-quoteless post-content"><h1 id=attempting-timing-attacks-against-scudo>Attempting Timing Attacks against <em>Scudo</em></h1><p>In this second blog post we will take a different approach for attacking <a href="https://cs.android.com/android/platform/superproject/+/android-12.0.0_r31:external/scudo/;bpv=0;bpt=0" target=_blank rel=noopener><em>Scudo</em></a>
, i.e. we will try to the measure execution times for calls to <code>malloc</code> and hope to be able to derive a portion of the internal state of the allocator (i.e. perform side channel attacks). The version of Scudo considered in this blog post is <a href="https://cs.android.com/android/platform/superproject/+/android-12.0.0_r31:external/scudo/METADATA;l=19;drc=45e1036faa0dcfa30a01982880be1137d441333d" target=_blank rel=noopener><code>161cca266a9d0b6deb5f1fd2de8ad543649a7fa1</code></a>
.</p><p>There will be almost only negative results (which means I unfortunately could not make it work), except for one. The main conclusion we can draw from this post is that <em>Scudo</em> is <strong>not</strong> designed to mitigate timing attacks! This follows from trying to leak a piece of information and then accidentally leaking a different and unclassified piece.</p><p><strong>Disclaimer</strong>: The following analyses can be incomplete and/or incorrect. Also the experiments conducted are on a <strong>very</strong> basic level compared to the complex field of <em>Data Science</em>. The style of this post is informal and chosen based on the idea of practical attacks on Android.</p><h2 id=experimental-setup>Experimental Setup</h2><p>As usual, there is a module for the <em>damnvulnerableapp</em> of the form:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-C data-lang=C><span class=line><span class=cl><span class=n>JNIEXPORT</span> <span class=n>jbyteArray</span> <span class=n>JNICALL</span>
</span></span><span class=line><span class=cl><span class=nf>Java_com_damnvulnerableapp_vulnerable_modules_HeapSCAModule_handleMessage</span><span class=p>(</span><span class=n>JNIEnv</span> <span class=o>*</span><span class=n>env</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                                                          <span class=n>jclass</span> <span class=n>class</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                                                          <span class=n>jbyteArray</span> <span class=n>message</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=kt>uint32_t</span> <span class=n>length</span> <span class=o>=</span> <span class=p>(</span><span class=o>*</span><span class=n>env</span><span class=p>)</span><span class=o>-&gt;</span><span class=nf>GetArrayLength</span><span class=p>(</span><span class=n>env</span><span class=p>,</span> <span class=n>message</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>length</span> <span class=o>==</span> <span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=nb>NULL</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>jbyte</span> <span class=o>*</span><span class=n>raw</span> <span class=o>=</span> <span class=p>(</span><span class=o>*</span><span class=n>env</span><span class=p>)</span><span class=o>-&gt;</span><span class=nf>GetByteArrayElements</span><span class=p>(</span><span class=n>env</span><span class=p>,</span> <span class=n>message</span><span class=p>,</span> <span class=nb>NULL</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>raw</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>jbyteArray</span> <span class=n>result</span> <span class=o>=</span> <span class=p>(</span><span class=o>*</span><span class=n>env</span><span class=p>)</span><span class=o>-&gt;</span><span class=nf>NewByteArray</span><span class=p>(</span><span class=n>env</span><span class=p>,</span> <span class=mi>8</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>switch</span> <span class=p>(</span><span class=n>raw</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=k>case</span> <span class=mi>0</span><span class=o>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=c1>// Malloc
</span></span></span><span class=line><span class=cl><span class=c1></span>                <span class=kt>uint64_t</span> <span class=n>size</span> <span class=o>=</span> <span class=o>*</span><span class=p>((</span><span class=kt>uint64_t</span><span class=o>*</span><span class=p>)</span><span class=o>&amp;</span><span class=n>raw</span><span class=p>[</span><span class=mi>1</span><span class=p>]);</span>
</span></span><span class=line><span class=cl>                <span class=kt>uint8_t</span> <span class=o>*</span><span class=n>ptr</span><span class=p>;</span>
</span></span><span class=line><span class=cl>                <span class=n>ptr</span> <span class=o>=</span> <span class=nf>malloc</span><span class=p>(</span><span class=n>size</span><span class=p>);</span>
</span></span><span class=line><span class=cl>                <span class=p>(</span><span class=o>*</span><span class=n>env</span><span class=p>)</span><span class=o>-&gt;</span><span class=nf>SetByteArrayRegion</span><span class=p>(</span><span class=n>env</span><span class=p>,</span> <span class=n>result</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=p>(</span><span class=n>jbyte</span><span class=o>*</span><span class=p>)</span><span class=o>&amp;</span><span class=n>ptr</span><span class=p>);</span>
</span></span><span class=line><span class=cl>                <span class=k>break</span><span class=p>;</span>
</span></span><span class=line><span class=cl>            <span class=p>}</span>
</span></span><span class=line><span class=cl>            <span class=k>case</span> <span class=mi>1</span><span class=o>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=c1>// Free
</span></span></span><span class=line><span class=cl><span class=c1></span>                <span class=kt>uint8_t</span> <span class=o>*</span><span class=n>ptr</span> <span class=o>=</span> <span class=p>(</span><span class=kt>uint8_t</span><span class=o>*</span><span class=p>)(</span><span class=o>*</span><span class=p>(</span><span class=kt>uint64_t</span><span class=o>*</span><span class=p>)</span><span class=o>&amp;</span><span class=n>raw</span><span class=p>[</span><span class=mi>1</span><span class=p>]);</span>
</span></span><span class=line><span class=cl>                <span class=nf>free</span><span class=p>(</span><span class=n>ptr</span><span class=p>);</span>
</span></span><span class=line><span class=cl>                <span class=p>(</span><span class=o>*</span><span class=n>env</span><span class=p>)</span><span class=o>-&gt;</span><span class=nf>SetByteArrayRegion</span><span class=p>(</span><span class=n>env</span><span class=p>,</span> <span class=n>result</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=p>(</span><span class=n>jbyte</span><span class=o>*</span><span class=p>)</span><span class=o>&amp;</span><span class=n>ptr</span><span class=p>);</span>
</span></span><span class=line><span class=cl>                <span class=k>break</span><span class=p>;</span>
</span></span><span class=line><span class=cl>            <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>result</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=nb>NULL</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>This module lets the user directly control whether and how to call <code>malloc</code> and <code>free</code>, or, to be more precise, <a href="https://cs.android.com/android/platform/superproject/+/android-12.0.0_r31:external/scudo/standalone/combined.h;l=292;bpv=0;bpt=0" target=_blank rel=noopener><code>Allocator::allocate</code></a>
and <a href="https://cs.android.com/android/platform/superproject/+/android-12.0.0_r31:external/scudo/standalone/combined.h;l=507;bpv=0;bpt=0" target=_blank rel=noopener><code>Allocator::deallocate</code></a>
. The input is composed like this: <code>&lt;func id>&lt;size | ptr></code> (9 bytes).</p><p><em>damnvulnerableapp</em> is run in an <em>x86-64</em> emulator (Pixel 3) running Android 12 and forwards <em>remote</em> user requests to the above module. It is already expected to see a lot of timing noise based on this setup.</p><p>Notice that measuring execution time of a remote call to e.g. <code>malloc(0x10)</code> (primary allocation) will actually measure execution time of a call to <code>Java_com_damnvulnerableapp_vulnerable_modules_HeapSCAModule_handleMessage</code>, which is called from Java.</p><p>As regards the client used to communicate with the app, it is written in <em>C</em>, thus it is expected to run faster than the former <em>Python</em> client. Because <em>damnvulnerableapp</em> uses a request - response model, i.e. a client has to request e.g. <code>malloc(0x10)</code>, gets a response that the request &ldquo;worked&rdquo; and then has to fetch the result with a second request, the time measurements are conducted as follows:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-C data-lang=C><span class=line><span class=cl><span class=k>struct</span> <span class=n>timespec</span> <span class=n>before</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=k>struct</span> <span class=n>timespec</span> <span class=n>after</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>...</span>
</span></span><span class=line><span class=cl><span class=c1>// Request malloc(0x10)
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=nf>app_forward</span><span class=p>(</span><span class=n>fd</span><span class=p>,</span> <span class=p>(</span><span class=kt>uint8_t</span><span class=o>*</span><span class=p>)</span><span class=n>message</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>buffer</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>buffer_length</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>before</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// Free response buffer
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=nf>free</span><span class=p>(</span><span class=n>buffer</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// Request result of malloc(0x10)
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=nf>app_fetch</span><span class=p>(</span><span class=n>fd</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>buffer</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>buffer_length</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>after</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// Extract result from response
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=n>pointer</span> <span class=o>=</span> <span class=o>*</span><span class=p>(</span><span class=kt>uint64_t</span><span class=o>*</span><span class=p>)</span><span class=nf>get_content</span><span class=p>(</span><span class=n>buffer</span><span class=p>,</span> <span class=n>buffer_length</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// Free response buffer
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=nf>free</span><span class=p>(</span><span class=n>buffer</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>...</span>
</span></span></code></pre></div><p><code>app_fetch</code> and <code>app_forward</code> (internally call <code>app_send_formatted</code>) are the core of this client:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-C data-lang=C><span class=line><span class=cl><span class=k>enum</span> <span class=n>error_code</span> <span class=nf>app_fetch</span><span class=p>(...)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=p>...</span>
</span></span><span class=line><span class=cl>    <span class=n>result</span> <span class=o>=</span> <span class=nf>app_send_formatted</span><span class=p>(</span><span class=n>fd</span><span class=p>,</span> <span class=s>&#34;CONTENT&#34;</span><span class=p>,</span> <span class=s>&#34;FETCH&#34;</span><span class=p>,</span> <span class=p>(</span><span class=kt>uint8_t</span><span class=o>*</span><span class=p>)</span><span class=s>&#34;&#34;</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=nb>NULL</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>result</span> <span class=o>!=</span> <span class=n>error_success</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nf>log_error</span><span class=p>(</span><span class=s>&#34;Failed to forward buffer&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>result</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>result</span> <span class=o>=</span> <span class=nf>app_full_read</span><span class=p>(</span><span class=n>fd</span><span class=p>,</span> <span class=n>buffer</span><span class=p>,</span> <span class=n>buffer_size</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>result</span> <span class=o>!=</span> <span class=n>error_success</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nf>log_error</span><span class=p>(</span><span class=s>&#34;Failed to read response to forward&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>result</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>// Measure time after fetching result
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>if</span> <span class=p>(</span><span class=n>after_receive</span> <span class=o>!=</span> <span class=nb>NULL</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nf>clock_gettime</span><span class=p>(</span><span class=n>CLOCK_THREAD_CPUTIME_ID</span><span class=p>,</span> <span class=n>after_receive</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=p>...</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>enum</span> <span class=n>error_code</span> <span class=nf>app_send_formatted</span><span class=p>(...)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=p>...</span>
</span></span><span class=line><span class=cl>    <span class=c1>// Measure time before forwarding message
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>if</span> <span class=p>(</span><span class=n>before_send</span> <span class=o>!=</span> <span class=nb>NULL</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nf>clock_gettime</span><span class=p>(</span><span class=n>CLOCK_THREAD_CPUTIME_ID</span><span class=p>,</span> <span class=n>before_send</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>result</span> <span class=o>=</span> <span class=nf>app_full_write</span><span class=p>(</span><span class=n>fd</span><span class=p>,</span> <span class=n>buffer</span><span class=p>,</span> <span class=n>buffer_size</span> <span class=o>+</span> <span class=n>content_length</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=nf>free</span><span class=p>(</span><span class=n>buffer</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>result</span> <span class=o>!=</span> <span class=n>error_success</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nf>log_error</span><span class=p>(</span><span class=s>&#34;Failed to send request&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>result</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>...</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>Because of the request - response model, there is additional noise introduced by being forced to make two remote requests for one e.g. <code>malloc(0x10)</code>!</p><p>Lets again summarize expected sources of noise introduced by the experimental setup:</p><ol><li>Android OS is emulated and therefore does not behave like an Android OS running on a &ldquo;real&rdquo; device (e.g. in terms of CPU power and scheduling)</li><li>Remote access to <em>damnvulnerableapp</em>. Although the emulator that runs the app is launched within the same device we will perform the measurements with, this is an additional layer of indirection.</li><li>Call to e.g. <code>malloc</code> is actually a call to <code>handleMessage</code>, which has to be invoked from Java. The call stack is pretty deep&mldr;</li><li>Two requests per operation</li></ol><h2 id=timing-attacks>Timing Attacks</h2><p>In this section, timing attacks on different targets within <em>Scudo</em> will be discussed.</p><h3 id=attacking-chunks-array>Attacking Chunks Array</h3><p>The core idea is to abuse a timing side channel on <code>Allocator::allocate</code>, i.e. calling <code>malloc</code> in <em>damnvulnerableapp</em>. <a href="https://cs.android.com/android/platform/superproject/+/android-12.0.0_r31:external/scudo/standalone/local_cache.h;l=69;drc=b45a2ea782074944f79fc388df20b06e01f265f7;bpv=0;bpt=1" target=_blank rel=noopener><code>C->Count</code></a>
will be the target of the attack, i.e. based on the measured execution times, we try to estimate the value of <code>C->Count</code>.</p><p>One may ask, why <code>C->Count</code> is interesting. There are two reasons:</p><ol><li>The chunk arrays are shuffled to, among other things, prevent an attacker from predicting where the next allocated chunk will be located. E.g. this can prevent heap overflows. Knowing <code>C->Count</code> looks like the first natural step to predicting how the array looks like in terms of address ordering.</li><li><code>SizeClassAllocatorLocalCache::allocate</code> contains a classical pattern for a timing side channel:<div class=highlight><pre tabindex=0 class=chroma><code class=language-C++ data-lang=C++><span class=line><span class=cl><span class=kt>void</span> <span class=o>*</span><span class=nf>allocate</span><span class=p>(</span><span class=n>uptr</span> <span class=n>ClassId</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=p>...</span>
</span></span><span class=line><span class=cl>    <span class=n>PerClass</span> <span class=o>*</span><span class=n>C</span> <span class=o>=</span> <span class=o>&amp;</span><span class=n>PerClassArray</span><span class=p>[</span><span class=n>ClassId</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>C</span><span class=o>-&gt;</span><span class=n>Count</span> <span class=o>==</span> <span class=mi>0</span><span class=p>)</span> <span class=p>{</span>    <span class=c1>// If C-&gt;Count = 0, then execution time is longer than &#34;usual&#34;
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=p>...</span>
</span></span><span class=line><span class=cl>        <span class=n>refill</span><span class=p>(</span><span class=n>C</span><span class=p>,</span> <span class=n>ClassId</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=p>...</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=c1>// The rest is very fast
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=p>...</span>
</span></span><span class=line><span class=cl>    <span class=n>CompactPtrT</span> <span class=n>CompactP</span> <span class=o>=</span> <span class=n>C</span><span class=o>-&gt;</span><span class=n>Chunks</span><span class=p>[</span><span class=o>--</span><span class=n>C</span><span class=o>-&gt;</span><span class=n>Count</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=p>...</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>Allocator</span><span class=o>-&gt;</span><span class=n>decompactPtr</span><span class=p>(</span><span class=n>ClassId</span><span class=p>,</span> <span class=n>CompactP</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div></li></ol><p>When allocating memory from the primary allocator via e.g. <code>malloc(0x10)</code>, then there is a number of allocations that will result in triggering <a href="https://cs.android.com/android/platform/superproject/+/android-12.0.0_r31:external/scudo/standalone/local_cache.h;l=69;drc=b45a2ea782074944f79fc388df20b06e01f265f7" target=_blank rel=noopener><code>C->Count == 0</code></a>
, which again triggers execution of <a href="https://cs.android.com/android/platform/superproject/+/android-12.0.0_r31:external/scudo/standalone/local_cache.h;l=169;drc=b45a2ea782074944f79fc388df20b06e01f265f7" target=_blank rel=noopener><code>refill</code></a>
. Afterwards, assuming that batches are only pushed back through <a href="https://cs.android.com/android/platform/superproject/+/android-12.0.0_r31:external/scudo/standalone/local_cache.h;l=182;drc=b45a2ea782074944f79fc388df20b06e01f265f7" target=_blank rel=noopener><code>drain</code></a>
or are newly allocated via <a href="https://cs.android.com/android/platform/superproject/+/android-12.0.0_r31:external/scudo/standalone/primary64.h;l=361;drc=b45a2ea782074944f79fc388df20b06e01f265f7" target=_blank rel=noopener><code>map</code></a>
, we can distinguish the following cases for <code>C->Count</code>:</p><ol><li><a href="https://cs.android.com/android/platform/superproject/+/android-12.0.0_r31:external/scudo/standalone/local_cache.h;l=183;drc=b45a2ea782074944f79fc388df20b06e01f265f7" target=_blank rel=noopener><code>C->Count = C->MaxCount / 2</code></a>
. This stems from the fact that <a href="https://cs.android.com/android/platform/superproject/+/android-12.0.0_r31:external/scudo/standalone/local_cache.h;l=84;drc=b45a2ea782074944f79fc388df20b06e01f265f7" target=_blank rel=noopener><code>deallocate</code></a>
can create batches if the corresponding <code>Chunks</code> array is full. To be precise, this will trigger the execution of <a href="https://cs.android.com/android/platform/superproject/+/android-12.0.0_r31:external/scudo/standalone/local_cache.h;l=182;drc=b45a2ea782074944f79fc388df20b06e01f265f7" target=_blank rel=noopener><code>drain</code></a>
, where <code>C->Count = C->MaxCount</code>. Therefore the minimum <code>Count = Min(C->MaxCount / 2, C->Count)</code> in <code>drain</code> will evaluate to <code>0 &lt; C->MaxCount / 2 &lt; C->MaxCount</code>. Finally, <code>C->Count -= Count &lt;=> C->Count = C->MaxCount - C->MaxCount / 2 = C->MaxCount / 2</code>. Notice that <a href="https://cs.android.com/android/platform/superproject/+/android-12.0.0_r31:external/scudo/standalone/local_cache.h;l=153;drc=b45a2ea782074944f79fc388df20b06e01f265f7;bpv=1;bpt=1" target=_blank rel=noopener><code>C->MaxCount = 2 * TransferBatch::getMaxCached(Size)</code></a>
. As can be seen in the next step, for <code>malloc(0x10)</code>, this will result in <code>C->MaxCount = 2 * 13 = 26 => C->Count = 26 / 2 = 13</code>.</li><li><a href="https://cs.android.com/android/platform/superproject/+/android-12.0.0_r31:external/scudo/standalone/primary64.h;l=396;drc=b45a2ea782074944f79fc388df20b06e01f265f7" target=_blank rel=noopener><code>C->Count = MaxCount</code></a>
, i.e.:</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-C++ data-lang=C++><span class=line><span class=cl><span class=n>C</span><span class=o>-&gt;</span><span class=n>Count</span> <span class=o>=</span> <span class=n>MaxCount</span>
</span></span><span class=line><span class=cl>         <span class=o>=</span> <span class=n>TransferBatch</span><span class=o>::</span><span class=n>getMaxCached</span><span class=p>(</span><span class=n>Size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>         <span class=o>=</span> <span class=n>Min</span><span class=p>(</span><span class=n>MaxNumCached</span><span class=p>,</span> <span class=n>SizeClassMap</span><span class=o>::</span><span class=n>getMaxCachedHint</span><span class=p>(</span><span class=n>Size</span><span class=p>))</span>
</span></span><span class=line><span class=cl>         <span class=o>=</span> <span class=n>Min</span><span class=p>(</span><span class=mi>13</span><span class=p>,</span> <span class=n>Max</span><span class=p>(</span><span class=mi>1U</span><span class=p>,</span> <span class=n>Min</span><span class=p>(</span><span class=n>Config</span><span class=o>::</span><span class=n>MaxNumCachedHint</span><span class=p>,</span> <span class=n>N</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>         <span class=o>=</span> <span class=n>Min</span><span class=p>(</span><span class=mi>13</span><span class=p>,</span> <span class=n>Max</span><span class=p>(</span><span class=mi>1U</span><span class=p>,</span> <span class=n>Min</span><span class=p>(</span><span class=mi>13</span><span class=p>,</span> <span class=p>(</span><span class=mi>1U</span> <span class=o>&lt;&lt;</span> <span class=n>Config</span><span class=o>::</span><span class=n>MaxBytesCachedLog</span><span class=p>)</span> <span class=o>/</span> <span class=k>static_cast</span><span class=o>&lt;</span><span class=n>u32</span><span class=o>&gt;</span><span class=p>(</span><span class=n>Size</span><span class=p>))))</span>
</span></span><span class=line><span class=cl>         <span class=o>=</span> <span class=n>Min</span><span class=p>(</span><span class=mi>13</span><span class=p>,</span> <span class=n>Max</span><span class=p>(</span><span class=mi>1U</span><span class=p>,</span> <span class=n>Min</span><span class=p>(</span><span class=mi>13</span><span class=p>,</span> <span class=p>(</span><span class=mi>1U</span> <span class=o>&lt;&lt;</span> <span class=mi>13</span><span class=p>)</span> <span class=o>/</span> <span class=n>Classes</span><span class=p>[</span><span class=n>ClassId</span> <span class=o>-</span> <span class=mi>1</span><span class=p>])))</span>
</span></span></code></pre></div><p>where <a href="https://cs.android.com/android/platform/superproject/+/android-12.0.0_r31:external/scudo/standalone/size_class_map.h;l=269;drc=b45a2ea782074944f79fc388df20b06e01f265f7" target=_blank rel=noopener><code>Classes</code></a>
:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-C++ data-lang=C++><span class=line><span class=cl><span class=k>static</span> <span class=k>constexpr</span> <span class=n>u32</span> <span class=n>Classes</span><span class=p>[]</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=mh>0x00020</span><span class=p>,</span> <span class=mh>0x00030</span><span class=p>,</span> <span class=mh>0x00040</span><span class=p>,</span> <span class=mh>0x00050</span><span class=p>,</span> <span class=mh>0x00060</span><span class=p>,</span> <span class=mh>0x00070</span><span class=p>,</span> <span class=mh>0x00080</span><span class=p>,</span> <span class=mh>0x00090</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=mh>0x000a0</span><span class=p>,</span> <span class=mh>0x000b0</span><span class=p>,</span> <span class=mh>0x000c0</span><span class=p>,</span> <span class=mh>0x000e0</span><span class=p>,</span> <span class=mh>0x000f0</span><span class=p>,</span> <span class=mh>0x00110</span><span class=p>,</span> <span class=mh>0x00120</span><span class=p>,</span> <span class=mh>0x00130</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=mh>0x00150</span><span class=p>,</span> <span class=mh>0x00160</span><span class=p>,</span> <span class=mh>0x00170</span><span class=p>,</span> <span class=mh>0x00190</span><span class=p>,</span> <span class=mh>0x001d0</span><span class=p>,</span> <span class=mh>0x00210</span><span class=p>,</span> <span class=mh>0x00240</span><span class=p>,</span> <span class=mh>0x002a0</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=mh>0x00330</span><span class=p>,</span> <span class=mh>0x00370</span><span class=p>,</span> <span class=mh>0x003a0</span><span class=p>,</span> <span class=mh>0x00400</span><span class=p>,</span> <span class=mh>0x00430</span><span class=p>,</span> <span class=mh>0x004a0</span><span class=p>,</span> <span class=mh>0x00530</span><span class=p>,</span> <span class=mh>0x00610</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=mh>0x00730</span><span class=p>,</span> <span class=mh>0x00840</span><span class=p>,</span> <span class=mh>0x00910</span><span class=p>,</span> <span class=mh>0x009c0</span><span class=p>,</span> <span class=mh>0x00a60</span><span class=p>,</span> <span class=mh>0x00b10</span><span class=p>,</span> <span class=mh>0x00ca0</span><span class=p>,</span> <span class=mh>0x00e00</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=mh>0x00fb0</span><span class=p>,</span> <span class=mh>0x01030</span><span class=p>,</span> <span class=mh>0x01130</span><span class=p>,</span> <span class=mh>0x011f0</span><span class=p>,</span> <span class=mh>0x01490</span><span class=p>,</span> <span class=mh>0x01650</span><span class=p>,</span> <span class=mh>0x01930</span><span class=p>,</span> <span class=mh>0x02010</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=mh>0x02190</span><span class=p>,</span> <span class=mh>0x02490</span><span class=p>,</span> <span class=mh>0x02850</span><span class=p>,</span> <span class=mh>0x02d50</span><span class=p>,</span> <span class=mh>0x03010</span><span class=p>,</span> <span class=mh>0x03210</span><span class=p>,</span> <span class=mh>0x03c90</span><span class=p>,</span> <span class=mh>0x04090</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=mh>0x04510</span><span class=p>,</span> <span class=mh>0x04810</span><span class=p>,</span> <span class=mh>0x05c10</span><span class=p>,</span> <span class=mh>0x06f10</span><span class=p>,</span> <span class=mh>0x07310</span><span class=p>,</span> <span class=mh>0x08010</span><span class=p>,</span> <span class=mh>0x0c010</span><span class=p>,</span> <span class=mh>0x10010</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>};</span>
</span></span></code></pre></div><p>So for a small allocation, i.e. for <code>ClassId = 1</code>, we get:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-C++ data-lang=C++><span class=line><span class=cl><span class=n>C</span><span class=o>-&gt;</span><span class=n>Count</span> <span class=o>=</span> <span class=n>Min</span><span class=p>(</span><span class=mi>13</span><span class=p>,</span> <span class=n>Max</span><span class=p>(</span><span class=mi>1U</span><span class=p>,</span> <span class=n>Min</span><span class=p>(</span><span class=mi>13</span><span class=p>,</span> <span class=mh>0x2000</span> <span class=o>/</span> <span class=mh>0x20</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>         <span class=o>=</span> <span class=n>Min</span><span class=p>(</span><span class=mi>13</span><span class=p>,</span> <span class=n>Max</span><span class=p>(</span><span class=mi>1U</span><span class=p>,</span> <span class=n>Min</span><span class=p>(</span><span class=mi>13</span><span class=p>,</span> <span class=mi>256</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>         <span class=o>=</span> <span class=n>Min</span><span class=p>(</span><span class=mi>13</span><span class=p>,</span> <span class=n>Max</span><span class=p>(</span><span class=mi>1U</span><span class=p>,</span> <span class=mi>13</span><span class=p>))</span>
</span></span><span class=line><span class=cl>         <span class=o>=</span> <span class=mi>13</span>
</span></span></code></pre></div><p>Notice that <code>C->Count = MaxCount</code> is true for all batches added to <code>FreeList</code> except for the last one, because <code>N</code> depends on a minimum:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-C++ data-lang=C++><span class=line><span class=cl><span class=k>for</span> <span class=p>(</span><span class=n>u32</span> <span class=n>I</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>I</span> <span class=o>&lt;</span> <span class=n>NumberOfBlocks</span><span class=p>;)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>TransferBatch</span> <span class=o>*</span><span class=n>B</span> <span class=o>=</span>
</span></span><span class=line><span class=cl>        <span class=n>C</span><span class=o>-&gt;</span><span class=n>createBatch</span><span class=p>(</span><span class=n>ClassId</span><span class=p>,</span> <span class=k>reinterpret_cast</span><span class=o>&lt;</span><span class=kt>void</span> <span class=o>*&gt;</span><span class=p>(</span><span class=n>decompactPtrInternal</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                                    <span class=n>CompactPtrBase</span><span class=p>,</span> <span class=n>ShuffleArray</span><span class=p>[</span><span class=n>I</span><span class=p>])));</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>UNLIKELY</span><span class=p>(</span><span class=o>!</span><span class=n>B</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=k>nullptr</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>const</span> <span class=n>u32</span> <span class=n>N</span> <span class=o>=</span> <span class=n>Min</span><span class=p>(</span><span class=n>MaxCount</span><span class=p>,</span> <span class=n>NumberOfBlocks</span> <span class=o>-</span> <span class=n>I</span><span class=p>);</span>    <span class=c1>// If (NumberOfBlocks - I &lt; MaxCount) =&gt; last iteration
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>B</span><span class=o>-&gt;</span><span class=n>setFromArray</span><span class=p>(</span><span class=o>&amp;</span><span class=n>ShuffleArray</span><span class=p>[</span><span class=n>I</span><span class=p>],</span> <span class=n>N</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>Region</span><span class=o>-&gt;</span><span class=n>FreeList</span><span class=p>.</span><span class=n>push_back</span><span class=p>(</span><span class=n>B</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>I</span> <span class=o>+=</span> <span class=n>N</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><h4 id=single---threaded-timing---based-side-channel-attack-on-primary>Single - Threaded Timing - Based Side Channel Attack on Primary</h4><p>Assuming that the only thread that accesses the <em>Scudo</em> primary for allocations of the form <code>malloc(0x10)</code> can be convinced to run this allocation with a constant, computable overhead. Then, the following attack might enable the prediction of <code>C->Count</code> based on measures of elapsed time:</p><ol><li>In iteration <code>j</code> perform 13 allocations (assuming classid 1 allocations, i.e. <code>malloc(0x10)</code>). For each allocation let <code>x_{i,j}</code> be the measured execution time (so <code>0 &lt;= i &lt;= 12</code>).</li><li>Add <code>x_{i,j}</code> to the list <code>X_i</code>.</li><li>After <code>0 &lt;= j &lt; num_iterations</code> 13 - chunk allocations, compute the average over each list. Let <code>x_i'</code> be the average of <code>X_i</code></li><li>Let <code>k := argmax_{0&lt;=i&lt;=12} x_i'</code></li><li>Return <code>k</code></li></ol><p>Consider the following visualization:<div class=not-prose><figure><img src=/2024/07/scudo_1_single_threaded_expectation_attack.png alt="Single Threaded Expectation Attack" loading=lazy></figure></div></p><p>From the diagram we can see that <code>C->Count = 4</code>. Now, if we start measuring the execution times, i.e. we get <code>x_{0,0}</code> for <code>C->Count = 4</code>, <code>x_{1,0}</code> for <code>C->Count = 3</code> etc. we can see that for <code>C->Count = 0</code> <code>x_{4,0}</code> is the biggest value. Therefore, right after <code>allocate</code> returns, the result <code>k = 4</code> of the above attack corresponds to the index of the biggest value <code>x_{4,0}</code>. Note that the second index is used to perform the 13 allocations multiple times in order to cancel out noise using the mean. Also, assuming that each call to <code>malloc</code> via <a href=#experimental-setup><code>handleMessage</code></a>
is only triggering this very <code>malloc</code>, i.e. there is no other call to <code>malloc</code> that influences <code>C->Count</code>, after the attack <code>C->Count</code> takes the same value it had before performing the attack (because <code>C->Count</code> is in mod 13 and we run <code>13 * num_iterations</code> allocations, which is divisible by 13).</p><p>Before the above attack, it may be beneficial to run a few allocations to ensure that <a href="https://cs.android.com/android/platform/superproject/+/android-12.0.0_r31:external/scudo/standalone/primary64.h;l=333;drc=b45a2ea782074944f79fc388df20b06e01f265f7;bpv=1;bpt=1" target=_blank rel=noopener><code>populateFreeList</code></a>
is called. This will result in <a href=#attacking-chunks-array><code>13</code></a>
chunks being available in <code>C->Chunks</code> and thus <code>C->Count = 13</code> right after <a href="https://cs.android.com/android/platform/superproject/+/android-12.0.0_r31:external/scudo/standalone/local_cache.h;l=74;bpv=0;bpt=1" target=_blank rel=noopener><code>refill</code></a>
and <code>C->Count = 12</code> right after <code>allocate</code> returns.</p><p>The main problem is that the assumptions are too strong for this attack to work on a real - world app. I.e. there are multiple threads that run <code>malloc(0x10)</code>. Therefore, the timings measured from the perspective of a single thread may be influenced by the following:</p><ol><li>Thread synchronization in <a href="https://cs.android.com/android/platform/superproject/+/android-12.0.0_r31:external/scudo/standalone/combined.h;l=356;drc=b45a2ea782074944f79fc388df20b06e01f265f7" target=_blank rel=noopener><code>Allocator::allocate</code></a>
. I.e. if there is another thread currently allocating memory via the primary, then our thread is forced to wait until the critical section is unlocked.</li><li>Between two calls to <code>malloc(0x10)</code>, there may be an arbitrary amount of threads that run <code>malloc(0x10)</code> due to scheduling. Therefore, the above attack, which assumes to be able to run 13 consecutive allocations in a row, is unlikely to work. This basically poisons the averages, which makes all of them look almost the same!</li><li>Remote call to <code>malloc</code> can trigger multiple allocations! Therefore, one measurement might decrease <code>C->Count</code> by two or more instead of one.</li></ol><h4 id=multithreaded-timing---based-side-channel-attacks-on-primary>Multithreaded Timing - Based Side Channel Attacks on Primary</h4><p>This section describes different approaches that aim to predict <code>C->Count</code> based on measured timings in a multithreaded environment.</p><h5 id=learn-distribution-from-leaked-counts>Learn Distribution from Leaked Counts</h5><p>Let <code>c_i</code> for <code>0 &lt;= i &lt; n</code> be the leaked values for <code>C->Count</code> from one thread (with fixed TSD) right before each <code>malloc(0x10)</code>. Notice that due to multithreading, this leaked value might differ from the value that is used in the following <code>malloc</code> call. We assume that the probability for this is negligible though.</p><p>Then compute for <code>0 &lt;= i &lt; n-1</code> the difference of the <code>C->Count</code> values, i.e. <code>d_i = -(c_{i+1} - c_{i}) mod 13</code>. With high probability, the <code>d_i</code> represent the amount of <code>malloc(0x10)</code> calls performed by other threads between each pair of <code>malloc(0x10)</code> calls performed by our thread. Remember that the <code>c_i</code> are leaked from our main thread.</p><p>Construct the probability distribution according to the frequencies of the <code>d_i</code> values. It is expected to be binomially distributed. Then, apply those probabilities to the timings. I.e. between each consecutive pair of time measurements <code>x_i</code> and <code>x_{i+1}</code> there is a random variable <code>D_i</code> distributed according to the above distribution.</p><p>Assuming we have a sequence of values for <code>C->Count</code> that is unknown, then every element in this unknown sequence can be represented as a random variable. To be precise, letting <code>C_i</code> be the random variables representing the <code>C->Count</code> before the i-th <code>malloc(0x10)</code>:</p><pre tabindex=0><code>C_{i+1} = C_i + D_i = C_i + D   // for all i: D_i are iid., so D~freq{d_i} is enough
</code></pre><p>Assuming that there is an anchor point, i.e. there exists a constant value <code>0 &lt;= C_0 &lt; 13</code> that is the first value for <code>C->Count</code>, then</p><pre tabindex=0><code>C_{i+1} = C_i + D = (((C_0 + D) + D) + ... ) + D = C_0 + (i + 1) * D
=&gt; E[C_{i+1}] = C_0 + (i+1) * E[D] = C_0 + (i+1) * (1/(n-1) * sum(d_i))
</code></pre><p>Given a sequence of timings <code>x_i</code> for <code>0 &lt;= i &lt; m</code> measured by calling <code>malloc(0x10)</code>, we could try to identify an anchor point, i.e. a point where <code>refill</code> was triggered by e.g. taking <code>max(x_i)</code>. If we get <code>x_k = max(x_i)</code>, then we performed <code>k + 1</code> allocations in order to get to this maximum value. Therefore, we could try to compute <code>E[C_k]</code> to get the expected value for <code>C->Count</code>, which is based on the above formula.</p><p>Unfortunately, there are some problems with this approach:</p><ol><li>Does not take into account that other threads still run <code>malloc(0x10)</code> in the background. Although this approach <em>might</em> work for computing the most probable value for <code>C->Count</code>, it would be invalidated the moment another thread called <code>malloc(0x10)</code>.</li><li>Probabilistic approach&mldr;in practice, this will most likely not be that much better than just guessing the value, because there are only so few possible values <code>C->Count</code> can take.</li></ol><h5 id=learn-thresholds>Learn Thresholds</h5><p>Another approach is to learn thresholds that distinguish a &ldquo;refill - timing&rdquo; from any other timing. Thus we will try to &ldquo;learn&rdquo; a threshold that allows for separating timings into either &ldquo;refill&rdquo; or &ldquo;non - refill&rdquo;. Although this approach might be too &ldquo;simple&rdquo;, because the problem can also be interpreted as distinguishing at least two guassian distributions, we can give it a try.</p><p>Initially, every thread is assigned to a <code>TSD</code> (linked to a cache, i.e. the <code>Chunks</code> array used in e.g. <a href="https://cs.android.com/android/platform/superproject/+/android-12.0.0_r31:external/scudo/standalone/local_cache.h;drc=b45a2ea782074944f79fc388df20b06e01f265f7;bpv=0;bpt=0;l=66" target=_blank rel=noopener><code>allocate</code></a>
, which is based on the primary) in a <a href="https://cs.android.com/android/platform/superproject/+/android-12.0.0_r31:external/scudo/standalone/tsd_shared.h;l=157;drc=b45a2ea782074944f79fc388df20b06e01f265f7;bpv=0;bpt=1" target=_blank rel=noopener>round - robin fashion</a>
. As experience showed that the app often has at least 20 threads, and <a href="https://cs.android.com/android/platform/superproject/+/android-12.0.0_r31:external/scudo/standalone/tsd_shared.h;l=33;drc=b45a2ea782074944f79fc388df20b06e01f265f7;bpv=0;bpt=1" target=_blank rel=noopener><code>NumberOfTSDs</code></a>
is either <a href="https://cs.android.com/android/platform/superproject/+/android-12.0.0_r31:external/scudo/standalone/allocator_config.h;l=109" target=_blank rel=noopener><code>DefaultTSDCount = 2</code></a>
or <a href="https://cs.android.com/android/platform/superproject/+/android-12.0.0_r31:external/scudo/standalone/linux.cpp;drc=b45a2ea782074944f79fc388df20b06e01f265f7;bpv=0;bpt=1;l=137" target=_blank rel=noopener><code>getNumberOfCPUs</code></a>
, which on the test system can at most be <code>8</code>, we can conclude that there are multiple threads referencing the same TSD. This is still better than having <strong>all</strong> threads sharing a single TSD!</p><p>As the UAF module (see previous posts on <em>Use - After - Free</em>) suggests that the current <code>TSD</code> of the JNI thread &ldquo;rarely&rdquo; changes (due to exploitation of the UAF module working almost always), in the following we will assume that we use the same TSD. We will also assume that there either is no other thread that references the current <code>TSD</code> or is at least one such thread, but this thread does not allocate often from the primary with classid 1.</p><p>Performing only primary allocations of size <code>0x10</code>, i.e. repeatedly calling a JNI function that calls <code>malloc(0x10)</code>, results in the following plot:<div class=not-prose><figure><img src=/2024/07/scudo_1_primary_alloc_only_4000_1.png alt="Primary Allocations(only) in form of malloc(0x10)" loading=lazy></figure></div></p><p>Further analysis of this plot reveals the following issues:</p><ol><li><p>There might exist 3 distinct distributions. I.e. it is possible to almost reliably (i.e. with high probability (whp)) differentiate between three different kinds of timings. This suggests that the types of timings are:</p><ol><li><code>refill</code> is called. Expected to be linked to the distribution with the highest mean.<ol><li><a href="https://cs.android.com/android/platform/superproject/+/android-12.0.0_r31:external/scudo/standalone/primary64.h;l=102;drc=b45a2ea782074944f79fc388df20b06e01f265f7" target=_blank rel=noopener><code>popBatch</code></a>
has a batch in the free list</li><li><code>popBatch</code> has to call <a href="https://cs.android.com/android/platform/superproject/+/android-12.0.0_r31:external/scudo/standalone/primary64.h;drc=b45a2ea782074944f79fc388df20b06e01f265f7;l=333" target=_blank rel=noopener><code>populateFreeList</code></a>
&ndash;> expected to take <strong>a lot of time</strong>.</li></ol></li><li><code>getTSDAndLock</code> takes longer, i.e. synchronization blocks execution.</li><li><code>allocate</code> instantly returns a chunk.</li></ol><p>Notice that currently, there is <strong>NO CERTAIN MAPPING</strong> between the first two types of timings and the two distributions with the highest means. However, whp. the distribution with the lowest mean is linked to the event that <code>allocate</code> instantly returns a chunk.</p></li><li><p>Assuming the distribution with the smallest mean is linked to the event that <code>allocate</code> instantly returns a chunk and that at least one distribution is caused by multithreading, then with probability at least <code>min(1394 / 4000, 1787 / 4000) = min(0.3485, 0.44675)</code> the TSD is shared with another thread.</p></li><li><p>Another &ldquo;distortion&rdquo; that could appear, but is very improbable, is that <a href="https://cs.android.com/android/platform/superproject/+/android-12.0.0_r31:external/scudo/standalone/combined.h;l=505;drc=b45a2ea782074944f79fc388df20b06e01f265f7;bpv=0;bpt=1" target=_blank rel=noopener><code>crc32</code></a>
calculation takes <strong>very</strong> long for specific values. As this has been empirically tested, this can be ruled out for now (I searched for values, which cause long execution times in the <code>crc32</code> instruction&mldr; without success).</p></li><li><p>Calling JNI functions can non - deterministically cause longer execution times e.g. by calling <code>malloc</code> internally.</p></li></ol><p>If the amount of points in the two distributions with the highest means are proportional to the total amount of points, then this rules out the possibility that the free list is filled with a lot of batches initially, because there can only be a constant amount of batches initially stored in the free list. Therefore, increasing the amount of allocations will reveal whether the amount of points in both distributions grows with the amount of allocations.</p><p>Also, notice that our thread will permanently allocate memory via <code>malloc(0x10)</code>. If there was another thread that freed memory using <code>free</code> on previously allocated classid - 1 chunks (assuming no memory leaks), then this cannot create a new batch, i.e. result in <code>drain</code> and therefore <code>pushBatch</code> being called, because our thread will not call <code>free</code> at all (of course there might be implicit calls to <code>free</code>, but they would not be part of <em>Scudo</em>). In addition to that, as Java threads have a 1 - 1 mapping with user - level threads (<code>pthread_create</code>), there cannot be multiple threads running <code>handleMessage</code>.</p><p>Interestingly, it turns out that one call to the JNI function may cause multiple internal <code>malloc</code> calls from the same or a TSD - sharing thread. E.g., if each remote <code>malloc</code> resulted in two malloc calls, i.e. one internal call and the call we requested, then, assuming <code>C->Count &lt; 13</code>, there will be six fast calls and one slow call. The timings used for analysis so far may contain multiple <code>malloc</code> calls, which explains the existence of three distributions. Two of those three distributions are actually the same only with shifted means, one contains the timings with only one <code>malloc</code>, the other one with two calls to <code>malloc</code>. This is due to the fact that <code>handleMessage</code> seems to call <code>malloc</code> at most twice, but at least once. Therefore, the distributions with the smallest and biggest means seem to represent one <code>malloc</code> and two mallocs without refill respectively, whereas the &ldquo;middle&rdquo; distribution seems to represent a single allocation with refill&mldr;although this does not really make sense, because there would have to be a lot of refills&mldr;</p><p>In order to prove that synchronization is an issue and that one call to <code>handleMessage</code> can cause two <code>malloc</code> calls, consider the following analysis (performed via gdb):</p><pre tabindex=0><code>&lt;Index of handleMessage call&gt;(length = &lt;amount cache allocations per handleMessage&gt;):
    &lt;Thread ID&gt;: count=&lt;C-&gt;Count value&gt;, id=&lt;Class ID&gt;

0(length = 0):
1(length = 1):
    20: count=0xb, id=0x00000020
2(length = 2):
    20: count=0xa, id=0x00000020
    20: count=0x9, id=0x00000020
3(length = 1):
    20: count=0x8, id=0x00000020
4(length = 2):
    20: count=0x7, id=0x00000020
    20: count=0x6, id=0x00000020
5(length = 0):
6(length = 0):
7(length = 2):
    20: count=0x5, id=0x00000020
    20: count=0x4, id=0x00000020
8(length = 2):
    20: count=0x3, id=0x00000020
    20: count=0x2, id=0x00000020
9(length = 1):
    20: count=0x1, id=0x00000020
10(length = 1):
    20: count=0x0, id=0x00000020
11(length = 1):
    20: count=0xc, id=0x00000020
12(length = 1):
    20: count=0xb, id=0x00000020
13(length = 0):
14(length = 2):
    20: count=0xa, id=0x00000020
    20: count=0x9, id=0x00000020
15(length = 0):
16(length = 0):
17(length = 1):
    20: count=0x8, id=0x00000020
18(length = 1):
    20: count=0x7, id=0x00000020
19(length = 0):
20(length = 2):
    20: count=0x6, id=0x00000020
    20: count=0x5, id=0x00000020
21(length = 1):
    20: count=0x4, id=0x00000020
22(length = 1):
    20: count=0x3, id=0x00000020
23(length = 0):
24(length = 1):
    20: count=0x2, id=0x00000020
25(length = 1):
    20: count=0x1, id=0x00000020
26(length = 0):
27(length = 2):
    20: count=0x0, id=0x00000020
    20: count=0xc, id=0x00000020
28(length = 1):
    20: count=0xb, id=0x00000020
29(length = 1):
    20: count=0xa, id=0x00000020
30(length = 0):
31(length = 0):
32(length = 2):
    20: count=0x9, id=0x00000020
    20: count=0x8, id=0x00000020
33(length = 1):
    20: count=0x7, id=0x00000020
34(length = 1):
    20: count=0x6, id=0x00000020
35(length = 3):
    20: count=0x5, id=0x00000020
    5: count=0x5, id=0x00000020
    20: count=0x4, id=0x00000020
36(length = 2):
    20: count=0x3, id=0x00000020
    20: count=0x2, id=0x00000020
37(length = 2):
    20: count=0x1, id=0x00000020
    20: count=0x0, id=0x00000020
38(length = 2):
    20: count=0xc, id=0x00000020
    20: count=0xb, id=0x00000020
39(length = 2):
    20: count=0xa, id=0x00000020
    20: count=0x9, id=0x00000020
40(length = 0):
41(length = 0):
42(length = 1):
    20: count=0x8, id=0x00000020
43(length = 1):
    20: count=0x7, id=0x00000020
44(length = 2):
    20: count=0x6, id=0x00000020
    20: count=0x5, id=0x00000020
45(length = 0):
46(length = 0):
47(length = 1):
    20: count=0x4, id=0x00000020
48(length = 0):
49(length = 1):
    20: count=0x3, id=0x00000020
50(length = 1):
    20: count=0x2, id=0x00000020
51(length = 1):
    20: count=0x1, id=0x00000020
52(length = 2):
    20: count=0x0, id=0x00000020
    20: count=0xc, id=0x00000020
53(length = 0):
54(length = 0):
55(length = 0):
56(length = 1):
    20: count=0xb, id=0x00000020
57(length = 1):
    20: count=0xa, id=0x00000020
58(length = 1):
    20: count=0x9, id=0x00000020
59(length = 2):
    20: count=0x8, id=0x00000020
    20: count=0x7, id=0x00000020
60(length = 0):
61(length = 2):
    20: count=0x6, id=0x00000020
    20: count=0x5, id=0x00000020
62(length = 0):
63(length = 0):
64(length = 0):
65(length = 0):
66(length = 1):
    20: count=0x4, id=0x00000020
67(length = 1):
    20: count=0x3, id=0x00000020
68(length = 1):
    20: count=0x2, id=0x00000020
69(length = 0):
70(length = 1):
    20: count=0x1, id=0x00000020
71(length = 0):
72(length = 1):
    20: count=0x0, id=0x00000020
73(length = 1):
    20: count=0xc, id=0x00000020
74(length = 1):
    20: count=0xb, id=0x00000020
75(length = 1):
    20: count=0xa, id=0x00000020
76(length = 2):
    20: count=0x9, id=0x00000020
    20: count=0x8, id=0x00000020
77(length = 2):
    20: count=0x7, id=0x00000020
    20: count=0x6, id=0x00000020
78(length = 8):
    5: count=0x5, id=0x00000020
    5: count=0x4, id=0x00000020
    5: count=0x3, id=0x00000020
    5: count=0x2, id=0x00000020
    5: count=0x2, id=0x00000020
    5: count=0x2, id=0x00000020
    5: count=0x2, id=0x00000020
    20: count=0x4, id=0x00000020
79(length = 3):
    5: count=0x4, id=0x00000020
    20: count=0x4, id=0x00000020
    20: count=0x3, id=0x00000020
80(length = 1):
    20: count=0x2, id=0x00000020
81(length = 2):
    20: count=0x1, id=0x00000020
    20: count=0x0, id=0x00000020
82(length = 1):
    20: count=0xc, id=0x00000020
83(length = 2):
    20: count=0xb, id=0x00000020
    20: count=0xa, id=0x00000020
84(length = 2):
    20: count=0x9, id=0x00000020
    20: count=0x8, id=0x00000020
85(length = 0):
86(length = 2):
    20: count=0x7, id=0x00000020
    20: count=0x6, id=0x00000020
87(length = 1):
    20: count=0x5, id=0x00000020
88(length = 1):
    20: count=0x4, id=0x00000020
89(length = 1):
    20: count=0x3, id=0x00000020
90(length = 1):
    20: count=0x2, id=0x00000020
91(length = 0):
92(length = 0):
93(length = 1):
    20: count=0x1, id=0x00000020
94(length = 2):
    20: count=0x0, id=0x00000020
    20: count=0xc, id=0x00000020
95(length = 2):
    20: count=0xb, id=0x00000020
    20: count=0xa, id=0x00000020
96(length = 0):
97(length = 1):
    20: count=0x9, id=0x00000020
</code></pre><p>Thread 20 is the main thread calling <code>handleMessage</code>. Its allocations are interleaved with allocations from thread 5. Notice that there are <strong>no</strong> inconsistencies in the above measurement, although it seems impossible for count to stay the same. This is due to thread 5 calling <code>free</code> in between calls to <code>malloc</code>.</p><p>Therefore, there is at least one other thread sharing the same TSD as our thread. As execution in <code>gdb</code> is &ldquo;weird&rdquo; sometimes, it can be assumed that multi - threading is even worse if no debugger is present. Overall, with at least one other thread interleaving and with uncertainty whether one call to <code>handleMessage</code> results in one or two calls to <code>malloc</code>, there seems to be no clear path to derive the actual value for <code>C->Count</code>.</p><h5 id=analysing-accurate-measurements>Analysing Accurate Measurements</h5><p>Performing timing analysis on the actual device, i.e. in the form of</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-C data-lang=C><span class=line><span class=cl><span class=nf>clock_gettime</span><span class=p>(</span><span class=n>CLOCK_THREAD_CPUTIME_ID</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>before</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=n>ptr</span> <span class=o>=</span> <span class=nf>malloc</span><span class=p>(</span><span class=n>size</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=nf>clock_gettime</span><span class=p>(</span><span class=n>CLOCK_THREAD_CPUTIME_ID</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>after</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=n>elapsed</span> <span class=o>=</span> <span class=p>(</span><span class=n>after</span><span class=p>.</span><span class=n>tv_sec</span> <span class=o>*</span> <span class=n>NS_PER_SECOND</span> <span class=o>+</span> <span class=n>after</span><span class=p>.</span><span class=n>tv_nsec</span><span class=p>)</span> <span class=o>-</span> <span class=p>(</span><span class=n>before</span><span class=p>.</span><span class=n>tv_sec</span> <span class=o>*</span> <span class=n>NS_PER_SECOND</span> <span class=o>+</span> <span class=n>before</span><span class=p>.</span><span class=n>tv_nsec</span><span class=p>);</span>
</span></span></code></pre></div><p>reveals an interesting and quite natural result:<div class=not-prose><figure><img src=/2024/07/scudo_1_primary_alloc_local_3316.png alt="Time Measurements performed locally on the emulator" loading=lazy></figure></div></p><p>Mapping three distributions to the same set of measurements yields:<div class=not-prose><figure><img src=/2024/07/scudo_1_primary_alloc_local_3316_3_dist.png alt="Time Measurements performed locally on the emulator (3 distributions)" loading=lazy></figure></div>.</p><p>Notice that these measurements are stripped off multiple layers of noise:</p><ol><li>Noise introduced by remote communication</li><li>Noise introduced by an arbitrary amount of function calls required for e.g. setting up a JNI call.</li><li>Some synchronization of threads. Notice that measuring the elapsed time for <code>malloc(0x10)</code> directly requires no further data fetching and therefore less threads are involved&mldr;</li></ol><h3 id=attacking-secondary-cache>Attacking Secondary Cache</h3><p>Naturally, we could also try to attack <strong>the</strong> secondary cache via a timing attack. As with classical cache - based side channel attacks, we would expect:</p><ol><li>fast execution time, if entry is in cache, i.e. <em>cache hit</em></li><li>slow execution time, if entry is <strong>not</strong> in cache, i.e. <em>cache miss</em></li></ol><p>Unfortunately, my experiments have been shut down by the fact that <strong>there is only one secondary for all threads</strong>. From experience, <em>damnvulnerableapp:VulnerableActivity</em> uses at least 20 threads. The experiment consisted of two events, i.e. <em>cache hit</em> and <em>cache miss</em>:</p><ol><li><p><em>cache hit</em>:</p><p>For the experiment, we repeat n times:</p><ol><li>Allocate chunk via secondary</li><li>Free chunk</li><li>Measure time required in 1.</li></ol><p>From the second iteration onwards, assuming no other threads steals the freed chunk from the cache, allocations are assumed to be fast. Statistics are taken over 400 measurements (repeated three times):</p><ol><li>avg = 351142.4975, var = 6215682405.529994, standard dev = 78839.59922228166; Without first: avg = 350635.6090225564, var = 6128486185.496259, standard dev = 78284.64846632614`</li><li>avg = 293603.4925, var = 9048178621.879944, standard dev = 95121.91451963078; Without first entry: 292885.1203007519, 8864432314.622118, 94151.11425056061</li><li>avg = 343784.9075, var = 8457856232.698944, standard dev = 91966.60389890966; Without first entry: 343308.24812030076, 8388172201.665255, 91586.96523886603</li></ol></li><li><p><em>cache miss</em>:</p><p>For the experiment, we repeat n times:</p><ol><li>Allocate chunk via secondary</li><li>Measure time required in 1.</li></ol><p>In the worst case, the first 32 allocations are covered by cache entries. Assuming that no other thread frees a lot of memory that results in chunks, which cover our requests, we end up with the following results (over 400 measurements, repeated twice):</p><ol><li>avg = 353609.1975, var = 7648425849.838493, standard dev = 87455.27914219069; Without first 32 entries: 354754.0652173913, 7595866298.691399, 87154.26724315567</li><li>avg = 320303.5725, var = 7655033941.299744, standard dev = 87493.05081719201; Without first 32 entries: 320182.16576086957, 7793835282.176328, 88282.70092252687</li></ol></li></ol><p>As can be seen from the repeated experiments, there seems to be no clear way for distinguishing secondary cache hits and misses. This might be due to the fact that there are roughly 20 threads sharing the same 32 cache entries! If we knew the distribution behind some random variable <code>X</code> that represents the amount of secondary <code>allocate</code> calls done in between two allocations performed by our thread, then we might be able to derive a probability distribution on the measured timings and maybe derive the most probable outcome, i.e. either cache hit or miss. But this seems like a rabbit hole, i.e. it does not seem to help in exploiting <em>Scudo</em>.</p><h2 id=conclusion>Conclusion</h2><p>So, what is the result of the above &ldquo;attacks&rdquo; that do not really achieve anything&mldr; Well, I argue that we actually achieved something without knowing that we achieved it, i.e. we can identify whether there are sometimes one and sometimes two calls to <code>malloc</code> when running <code>handleMessage</code>.</p><p>Recall the visualization of the measurements:<div class=not-prose><figure><img src=/2024/07/scudo_1_primary_alloc_only_4000_1.png alt="Primary Allocations(only) in form of malloc(0x10)" loading=lazy></figure></div></p><p>Of course, the above diagram is composed of measuring only 4000 execution times. Still, we can tell whether a new time measurement belongs to either the red or the blue distribution with high probability, if the assumption is correct that the red and blue distributions represent one and two calls to <code>malloc</code>, respectively! Adding to the pile, being able to distinguish time measurements like shown in the diagram suggests that there is some underlying information to be extracted. Notice that the distributions shown in the diagram come from time measurements taken over a JNI call and not a <code>malloc</code> call directly!</p><p>As can be seen from the measurements taken <a href=#analysing-accurate-measurements>locally</a>
, <em>Scudo</em> leaks information through execution times and thus is not designed to mitigate timing attacks. Further analyses are required to apply and evaluate the whole potential of side channel attacks on <em>Scudo</em>.</p><p>Unfortunately, I am neither a data scientist nor an expert in statistics or side channel attacks. Hence, the analyses conducted in this blog post are very basic and, again, might be incorrect and/or incomplete.</p><p>Therefore, attacking <em>Scudo</em> in terms of timing attacks has to be postponed until a corresponding expert joins the game.</p></article></div></div></div></main><footer class="flex flex-none justify-center"><section class="flex flex-col md:flex-row mx-2 md:mx-0 gap-2 md:gap-0 justify-between w-full max-w-4xl lg:max-w-5xl py-6 text-slate-500 dark:text-slate-300"><div class="flex flex-row"></div><div class=grow></div><div class="flex flex-row"><i class="h-6 w-6 flex-none"><svg class="icon icon-tabler icon-tabler-copyright" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M12 12m-9 0a9 9 0 1018 0A9 9 0 103 12"/><path d="M14 9.75a3.016 3.016.0 00-4.163.173 2.993 2.993.0 000 4.154A3.016 3.016.0 0014 14.25"/></svg>
</i>2022 - 2025 lolcads</div><div class="flex flex-row"><span class="ml-0 pl-0 md:ml-2 md:pl-2 border-l-0 md:border-l border-slate-300 dark:border-slate-400">Powered by <a href=https://gohugo.io target=_blank rel=noopener class=underline>Hugo</a> <span class=text-red-600>&#9829;</span> <a href=https://github.com/tomowang/hugo-theme-tailwind target=_blank rel=noopener class=underline>Tailwind</a></span></div></section></footer><script src=/main.min.c6372b6836971865bd94bfde974748aca8415824a2facab6ccd66a87384bfacb.js></script><div class="hidden top-1 right-1" id=code-copy><i class="h-6 w-6 block"><svg class="icon icon-tabler icon-tabler-copy" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M7 7m0 2.667A2.667 2.667.0 019.667 7h8.666A2.667 2.667.0 0121 9.667v8.666A2.667 2.667.0 0118.333 21H9.667A2.667 2.667.0 017 18.333z"/><path d="M4.012 16.737A2.005 2.005.0 013 15V5c0-1.1.9-2 2-2h10c.75.0 1.158.385 1.5 1"/></svg></i></div><div class="hidden top-1 right-1" id=code-copy-done><i class="h-6 w-6 block"><svg class="icon icon-tabler icon-tabler-check" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M5 12l5 5L20 7"/></svg></i></div><script src=/code-copy.min.e7b2a74adef1ed474c335c8bd5e7832b2316b8842b0f9184d65286c5bd64f51a.js></script></body></html>